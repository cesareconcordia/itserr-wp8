{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d767f59-fcc3-403b-81b6-565a495fb00b",
   "metadata": {},
   "source": [
    "### S_Vl: creazione del grafo RDF\n",
    "\n",
    "Questo notebook implementa una procedura per la creazione del grafo RDF del testo della S_Vl secondo gli assiomi dell'ontologia [TresOnt](https://docs.google.com/document/d/1n-OlAy1KleovGgHV4ZHhOSgkgMfsOKPDWT603_fic5k/edit?tab=t.0#heading=h.ng7sdvi05k6u).  \n",
    "\n",
    "__Grafo della struttura__ Il testo è trasformato in formato tabellare facendo il parsing dei file <a href=\"https://en.wikipedia.org/wiki/Open_Scripture_Information_Standard\">Open Scripture Information Standard (OSIS)</a> presenti nella <a href=\"https://drive.google.com/drive/folders/1KEFTwR1kLz1Ec_-vU3k-yoFcaynBoP7x\">cartella</a> del drive condiviso del WP8. Alle righe della tabella sono applicate le regole di trasformazione in triple.  \n",
    "__Grafo delle caratteristiche linguistiche__ Alle risorse della struttura sono associate le caratteristiche linguistiche ottenute da LiLa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c1d7a6-8d94-4c0c-b49d-72b932a731b6",
   "metadata": {},
   "source": [
    "####  Librerie e configurazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a77ef3-775b-4818-ab26-9b333ed0baa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "import rdflib\n",
    "from itserr_lib import OsisParser as op\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9869708e-78fb-42d3-9b83-425b2c2314a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.isfile('config-s_vl.yaml')):\n",
    "    configfile=\"config-s_vl.yaml\"\n",
    "else:\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), \"config-s_vl.yaml\")\n",
    "try:\n",
    "    with open(configfile, 'r') as stream:\n",
    "        try:\n",
    "            conf=yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "except FileNotFoundError:\n",
    "    print('Warning config.yaml file not present! Please create it and set the values, store it in the main directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27559b06-a410-4314-9999-5f21d10861be",
   "metadata": {},
   "source": [
    "#### 1 Creo il dataframe con il testo della Vulgata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5fefca1-e276-425f-a6f0-e1622c9368bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=conf['TEXTFILES']\n",
    "source=conf['LIBRI_S_VL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42dfaa78-04eb-4f52-b75e-abf146a3b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "opars=op()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "273eedc9-177a-4551-8bad-2d86585c61cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 135.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating IRIs...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "df_opera=opars.getDataFrame(source, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73403e9f-ac0a-43c3-a88e-107c09426036",
   "metadata": {},
   "source": [
    "#### 2 Applico le regole per la creazione del grafo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c643a-2eba-4b36-9bc1-506da415347f",
   "metadata": {},
   "source": [
    "Inizializzo la tabella con i lemmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f9dc5c-1699-4ba3-bdd5-79ba180de77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 366314 entries, 0 to 208564\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   token       366314 non-null  object\n",
      " 1   lemma       366314 non-null  object\n",
      " 2   upos        366314 non-null  object\n",
      " 3   spaceAfter  366314 non-null  object\n",
      " 4   linking     366314 non-null  object\n",
      " 5   irifrag     366314 non-null  int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 19.6+ MB\n"
     ]
    }
   ],
   "source": [
    "mydf0=pd.read_pickle('data/output/s_vl_lemmi_0k-5k.pickle')\n",
    "mydf1=pd.read_pickle('data/output/s_vl_lemmi_5k-10k.pickle')\n",
    "mydf2=pd.read_pickle('data/output/s_vl_lemmi_10k-e.pickle')\n",
    "df_lemmi=pd.concat([mydf0, mydf1, mydf2])\n",
    "df_lemmi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e70c6a34-4f00-4e0a-9f95-ecd84a8ada8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>libro</th>\n",
       "      <th>idverso</th>\n",
       "      <th>numcap</th>\n",
       "      <th>numverso</th>\n",
       "      <th>testo</th>\n",
       "      <th>irifrag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18104</th>\n",
       "      <td>acts</td>\n",
       "      <td>acts.8.16</td>\n",
       "      <td>acts.8</td>\n",
       "      <td>16</td>\n",
       "      <td>Nondum enim' in quemquam eorum de ciderat: sol...</td>\n",
       "      <td>18104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      libro    idverso  numcap  numverso  \\\n",
       "18104  acts  acts.8.16  acts.8        16   \n",
       "\n",
       "                                                   testo  irifrag  \n",
       "18104  Nondum enim' in quemquam eorum de ciderat: sol...    18104  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_opera[df_opera.libro.str.contains('acts') & df_opera.testo.str.contains('quemquam')].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b067cc2-1f4e-4c2d-86bd-437e9f784ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>spaceAfter</th>\n",
       "      <th>linking</th>\n",
       "      <th>irifrag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137101</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>17955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137124</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>17956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137131</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>17957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137221</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>17962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137362</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>17969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137369</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>17969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137798</th>\n",
       "      <td>invenimus</td>\n",
       "      <td>inuenio</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:108806]</td>\n",
       "      <td>17995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137812</th>\n",
       "      <td>invenimus</td>\n",
       "      <td>inuenio</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:108806]</td>\n",
       "      <td>17995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137870</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>17998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138011</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>18008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138402</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>18028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138442</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>18030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139015</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>18062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139164</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>18069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139578</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>18095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139714</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>18104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139795</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>18109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139821</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>18111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140113</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>18127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140317</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>18138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token    lemma  upos spaceAfter             linking  irifrag\n",
       "137101       enim     enim   ADV             [lilaLemma:101119]    17955\n",
       "137124       enim     enim   ADV             [lilaLemma:101119]    17956\n",
       "137131       enim     enim   ADV             [lilaLemma:101119]    17957\n",
       "137221       enim     enim   ADV             [lilaLemma:101119]    17962\n",
       "137362       enim     enim   ADV             [lilaLemma:101119]    17969\n",
       "137369       enim     enim   ADV             [lilaLemma:101119]    17969\n",
       "137798  invenimus  inuenio  VERB             [lilaLemma:108806]    17995\n",
       "137812  invenimus  inuenio  VERB             [lilaLemma:108806]    17995\n",
       "137870       enim     enim   ADV             [lilaLemma:101119]    17998\n",
       "138011       enim     enim   ADV             [lilaLemma:101119]    18008\n",
       "138402       enim     enim   ADV             [lilaLemma:101119]    18028\n",
       "138442       enim     enim   ADV             [lilaLemma:101119]    18030\n",
       "139015       enim     enim   ADV             [lilaLemma:101119]    18062\n",
       "139164       enim     enim   ADV             [lilaLemma:101119]    18069\n",
       "139578       enim     enim   ADV             [lilaLemma:101119]    18095\n",
       "139714       enim     enim   ADV             [lilaLemma:101119]    18104\n",
       "139795       enim     enim   ADV             [lilaLemma:101119]    18109\n",
       "139821       enim     enim   ADV             [lilaLemma:101119]    18111\n",
       "140113       enim     enim   ADV             [lilaLemma:101119]    18127\n",
       "140317       enim     enim   ADV             [lilaLemma:101119]    18138"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lemmi[df_lemmi.token.str.contains('enim')].iloc[1370:1390]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e0a17ad-223a-48eb-85cf-5e4023101f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>spaceAfter</th>\n",
       "      <th>linking</th>\n",
       "      <th>irifrag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139709</th>\n",
       "      <td>ut</td>\n",
       "      <td>ut</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:130906]</td>\n",
       "      <td>18103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139710</th>\n",
       "      <td>acciperent</td>\n",
       "      <td>accipio</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:87119]</td>\n",
       "      <td>18103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139711</th>\n",
       "      <td>Spiritum</td>\n",
       "      <td>spiritus</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:125406]</td>\n",
       "      <td>18103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139712</th>\n",
       "      <td>sanctum</td>\n",
       "      <td>sanctus</td>\n",
       "      <td>ADJ</td>\n",
       "      <td></td>\n",
       "      <td>[lilaIpoLemma:39324]</td>\n",
       "      <td>18103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139713</th>\n",
       "      <td>Nondum</td>\n",
       "      <td>nondum</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:114073]</td>\n",
       "      <td>18104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139714</th>\n",
       "      <td>enim</td>\n",
       "      <td>enim</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:101119]</td>\n",
       "      <td>18104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139715</th>\n",
       "      <td>'</td>\n",
       "      <td>'</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>18104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139716</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:106748]</td>\n",
       "      <td>18104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139717</th>\n",
       "      <td>quemquam</td>\n",
       "      <td>quisquam</td>\n",
       "      <td>PRON</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:121315]</td>\n",
       "      <td>18104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139718</th>\n",
       "      <td>eorum</td>\n",
       "      <td>is</td>\n",
       "      <td>DET</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:109083]</td>\n",
       "      <td>18104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139719</th>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:97932]</td>\n",
       "      <td>18104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139720</th>\n",
       "      <td>ciderat</td>\n",
       "      <td>cidero</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>18104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token     lemma   upos spaceAfter               linking  irifrag\n",
       "139709          ut        ut  SCONJ               [lilaLemma:130906]    18103\n",
       "139710  acciperent   accipio   VERB                [lilaLemma:87119]    18103\n",
       "139711    Spiritum  spiritus   NOUN               [lilaLemma:125406]    18103\n",
       "139712     sanctum   sanctus    ADJ             [lilaIpoLemma:39324]    18103\n",
       "139713      Nondum    nondum    ADV               [lilaLemma:114073]    18104\n",
       "139714        enim      enim    ADV               [lilaLemma:101119]    18104\n",
       "139715           '         '  PUNCT                               []    18104\n",
       "139716          in        in    ADP               [lilaLemma:106748]    18104\n",
       "139717    quemquam  quisquam   PRON               [lilaLemma:121315]    18104\n",
       "139718       eorum        is    DET               [lilaLemma:109083]    18104\n",
       "139719          de        de    ADP                [lilaLemma:97932]    18104\n",
       "139720     ciderat    cidero   VERB                               []    18104"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lemmi.loc[139709:139720]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3131d8-b0cd-4232-ace4-b9e0a60623b5",
   "metadata": {},
   "source": [
    "Inizializzo i namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d7806a6-60c4-44c1-bcd3-fbc0df1c43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.namespace import DC, DCAT, DCTERMS, OWL, \\\n",
    "                            RDF, RDFS, SKOS,  \\\n",
    "                           XMLNS, XSD, XMLNS\n",
    "from rdflib import Namespace\n",
    "from rdflib import URIRef, BNode, Literal\n",
    "its=Namespace(conf['NAMESPACES']['its'])\n",
    "ecrm=Namespace(conf['NAMESPACES']['ecrm'])\n",
    "ontolex=Namespace(conf['NAMESPACES']['ontolex'])\n",
    "tresont=Namespace(conf['NAMESPACES']['tresont'])\n",
    "lila=Namespace(conf['NAMESPACES']['lila'])\n",
    "orl=Namespace(conf['NAMESPACES']['orl'])\n",
    "lilaLemma=Namespace(conf['NAMESPACES']['lilaLemma'])\n",
    "lilaIpoLemma=Namespace(conf['NAMESPACES']['lilaIpoLemma'])\n",
    "\n",
    "siglaopera=conf['SIGLAOPERA']\n",
    "titoloopera=conf['TITOLOOPERA']\n",
    "idencodes=conf['TITOLILIBRI']\n",
    "sigleCat=conf['SIGLEPOS']\n",
    "punct=['.', ',', ':', ';', '?', '!', '†', '※', '(', ')', '-', '..', '\"', '[', ']', '•']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8d7682c-4da6-4fa8-9903-e5fc6e59b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "synt_rdf = rdflib.Graph(identifier = URIRef('https://itserr.it/struct'))\n",
    "lang_rdf = rdflib.Graph(identifier = URIRef('https://itserr.it/lang'))\n",
    "# Declare prefixes\n",
    "synt_rdf.bind(\"its\", its)\n",
    "synt_rdf.bind(\"ecrm\", ecrm)\n",
    "lang_rdf.bind(\"ecrm\", ecrm)\n",
    "synt_rdf.bind(\"tresont\", tresont)\n",
    "lang_rdf.bind(\"tresont\", tresont)\n",
    "synt_rdf.bind(\"orl\", orl)\n",
    "synt_rdf.bind(\"lila\", lila)\n",
    "lang_rdf.bind(\"lila\", lila)\n",
    "synt_rdf.bind(\"ontolex\", ontolex)\n",
    "lang_rdf.bind(\"ontolex\", ontolex)\n",
    "lang_rdf.bind(\"lilaLemma\", lilaLemma)\n",
    "lang_rdf.bind(\"lilaIpoLemma\", lilaIpoLemma)\n",
    "synt_rdf.bind(\"orl\", orl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4716ac7f-0073-4c2b-abfb-82295e6113e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=https://itserr.it/struct (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IRIs\n",
    "\n",
    "workiri=URIRef(its[f'{siglaopera}'])\n",
    "uritf=URIRef(tresont.TextFragment)\n",
    "uriinterval=URIRef(tresont.Interval)\n",
    "opirititle=URIRef(its[f'{siglaopera}_ti'])\n",
    "uritpi=URIRef(tresont.TextualPositionByIndex)\n",
    "urile=URIRef(ontolex.LexicalEntry)\n",
    "uriale= URIRef(tresont.AlphabetElement)\n",
    "uripunct= URIRef(tresont.PunctuationMark)\n",
    "uritilemma=URIRef(ontolex.Form)\n",
    "\n",
    "#Aggiungo le triple al grafo\n",
    "\n",
    "verseindividual=URIRef(tresont['verseType'])\n",
    "chapterindividual=URIRef(tresont['chapterType'])\n",
    "bookindividual=URIRef(tresont['bookType'])\n",
    "synt_rdf.add((verseindividual, RDF.type, tresont.StructuralType))\n",
    "synt_rdf.add((verseindividual, RDFS.label, Literal('Verse', lang='en')))\n",
    "synt_rdf.add((chapterindividual, RDF.type, tresont.StructuralType))\n",
    "synt_rdf.add((chapterindividual, RDFS.label, Literal('Chapter', lang='en')))\n",
    "synt_rdf.add((bookindividual, RDF.type, tresont.StructuralType))\n",
    "synt_rdf.add((bookindividual, RDFS.label, Literal('Book', lang='en')))\n",
    "\n",
    "synt_rdf.add((verseindividual, ecrm.P127_has_broader_term, chapterindividual))\n",
    "synt_rdf.add((chapterindividual, ecrm.P127_has_broader_term, bookindividual))\n",
    "\n",
    "libri=df_opera.libro.unique()\n",
    "synt_rdf.add((workiri, RDF.type, URIRef(tresont.OrderedTextualCollection)))\n",
    "synt_rdf.add((opirititle, RDF.type, ecrm.E35_title))\n",
    "synt_rdf.add((opirititle, RDFS.label, Literal(titoloopera, lang='la')))\n",
    "synt_rdf.add((workiri, ecrm.P102_has_title,opirititle))\n",
    "synt_rdf.add((workiri, tresont.hasLength, Literal(len(libri), datatype=XSD.integer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e829bb4-9572-4d22-90d8-3420ca75c2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gen' 'Ex' 'Lev' 'Num' 'Deut' 'Josh' 'Judg' 'Ruth' '1Sam' '2Sam' '1Kings'\n",
      " '2Kings' '1Chr' '2Chr' 'esdrae-2' 'Tob' 'Judith' 'Esth' 'Job' 'Prov'\n",
      " 'Eccl' 'Song' 'Wis' 'Sir' 'Is' 'Jeremiah' 'Ier' 'Bar' 'Ezek' 'Dan' 'Hos'\n",
      " 'Joel' 'Amos' 'Obad' 'Jonah' 'Mic' 'Nah' 'Hab' 'Zeph' 'Hag' 'Zech' 'Mal'\n",
      " '1Mac' '2Mac' 'matthew' 'mark' 'luke' 'john' 'acts' 'romans'\n",
      " 'corinthians-1' 'corinthians-2' 'galatians' 'ephesians' 'philippians'\n",
      " 'colossians' 'thessalonians-1' 'thessalonians-2' 'timothy-1' 'timothy-2'\n",
      " 'titus' 'philemon' 'hebrews' 'james' 'peter-1' 'peter-2' 'john-1'\n",
      " 'john-2' 'john-3' 'jude' 'revelation' 'esdrae-3']\n"
     ]
    }
   ],
   "source": [
    "print(libri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94dd8c78-2207-4a59-9a63-034bf03ba2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [01:39,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# creazione del grafo della struttura dell'opera\n",
    "from tqdm import tqdm\n",
    "bs=0\n",
    "idOp=siglaopera\n",
    "# for libro in tqdm(libri):\n",
    "for idlibro, libro in tqdm(enumerate(libri)):\n",
    "    libroLength=0\n",
    "    # idbasekey=f'{libro[0].upper()}{libro[1:]}'\n",
    "    idbasekey=f'{libro}'\n",
    "    # print(idbasekey)\n",
    "    idbase=idencodes[idbasekey][0].lower()\n",
    "    titololibro=idencodes[idbasekey][-1] #idbasekey\n",
    "    titololibrolat=idencodes[idbasekey][1]\n",
    "    titololibrolatalt=''\n",
    "    if (len(idencodes[idbasekey])==4):\n",
    "        titololibrolatalt=idencodes[idbasekey][2]\n",
    "    # print(f\" processing {idbase}, {titololibrolat}, {titololibrolatalt}\")\n",
    "    \n",
    "    bs=idlibro+1\n",
    "    \n",
    "    # LIBRO\n",
    "    libroiri=URIRef(its[f'{idOp}_{idbase}'])\n",
    "    libroirititle=URIRef(its[f'{idOp}_{idbase}_ti'])\n",
    "    libroiriseq=URIRef(its[f'{idOp}_{idbase}_{bs}_seq'])\n",
    "    synt_rdf.add((libroirititle, RDF.type, ecrm.E35_title))\n",
    "    synt_rdf.add((libroirititle, RDFS.label, Literal(titololibro, lang='en')))\n",
    "    synt_rdf.add((libroirititle, RDFS.label, Literal(titololibrolat, lang='la')))\n",
    "    if (titololibrolatalt!=''):\n",
    "        synt_rdf.add((libroirititle, SKOS.altLabel, Literal(titololibrolatalt, lang='la')))\n",
    "    synt_rdf.add((libroiri, RDF.type, tresont.Book))\n",
    "    synt_rdf.add((libroiri, ecrm.P102_has_title, libroirititle))\n",
    "    \n",
    "        \n",
    "    synt_rdf.add((libroiriseq, RDF.type, tresont.TextSequenceElement))\n",
    "    synt_rdf.add((libroiriseq, tresont.occurrenceOf, libroiri))\n",
    "    synt_rdf.add((libroiriseq,tresont.hasPosition, Literal(bs, datatype=XSD.integer)))\n",
    "    synt_rdf.add((libroiriseq,tresont.inSequence, workiri))\n",
    "    synt_rdf.add((workiri, tresont.hasSequenceElement, libroiriseq))\n",
    "    \n",
    "    testdf=df_opera[df_opera.libro==libro].copy() #seleziono i versetti del libro\n",
    "    \n",
    "    testdf.reset_index(drop=True, inplace=True)\n",
    "    cps={'test'}\n",
    "    prevchap=''\n",
    "    chaptokenindex=0\n",
    "    for i, v in testdf['testo'].items():\n",
    "       \n",
    "        # CAPITOLO\n",
    "\n",
    "        if (not testdf.iloc[i].numcap in cps):\n",
    "            idcapitolo=(testdf.iloc[i].numcap).split(\".\")[1]  \n",
    "            capoccintiri=URIRef(its[f'{idOp}_{idbase}_{idcapitolo}_i'])\n",
    "            capocciri=URIRef(its[f'{idOp}_{idbase}_{idcapitolo}_o'])\n",
    "            capiri=URIRef(its[f'{idOp}_{idbase}_{idcapitolo}_c_se'])\n",
    "            synt_rdf.add((capocciri, RDF.type, uritf))\n",
    "            synt_rdf.add((capocciri, tresont.hasStructuralType, chapterindividual))\n",
    "            synt_rdf.add((capocciri, tresont.hasNumber, Literal(idcapitolo, datatype=XSD.integer)))\n",
    "            synt_rdf.add((capocciri, tresont.inSequence, libroiri))\n",
    "            synt_rdf.add((capocciri, tresont.occurrenceOf, capiri))\n",
    "            synt_rdf.add((capiri, RDF.type, tresont.SyntacticEntity))\n",
    "            \n",
    "            #Intervallo del capitolo\n",
    "            synt_rdf.add((capocciri, tresont.hasInterval, capoccintiri))\n",
    "            synt_rdf.add((capoccintiri, RDF.type, uriinterval))\n",
    "            synt_rdf.add((capoccintiri, tresont.intervalFrom, Literal(libroLength+1, datatype=XSD.integer)))\n",
    "            if(prevchap==''):\n",
    "                prevchap=capoccintiri\n",
    "            else:\n",
    "                synt_rdf.add((prevchap, tresont.intervalTo, Literal(libroLength, datatype=XSD.integer)))\n",
    "                prevchap=capoccintiri\n",
    "            cps.add(testdf.iloc[i].numcap)\n",
    "        \n",
    "        #OCCORRENZA VERSO\n",
    "        versoocciri=URIRef(its[f'{idOp}_{idbase}_{idcapitolo}_{testdf.iloc[i].numverso}_o'])\n",
    "        versooccintiri=URIRef(its[f'{idOp}_{idbase}_{idcapitolo}_{testdf.iloc[i].numverso}_i'])\n",
    "        versoiri=URIRef(its[f'{idOp}_{testdf.iloc[i].irifrag}_v_se'])\n",
    "    \n",
    "        synt_rdf.add((versoocciri, RDF.type, uritf))\n",
    "        synt_rdf.add((versoocciri, tresont.hasStructuralType, verseindividual))\n",
    "        synt_rdf.add((versoocciri, tresont.hasNumber, Literal(testdf.iloc[i].numverso, datatype=XSD.integer)))\n",
    "        synt_rdf.add((versoocciri, tresont.inSequence, libroiri))\n",
    "        synt_rdf.add((versoocciri, tresont.inSequence, capocciri))\n",
    "        \n",
    "        #Intervallo del verso\n",
    "        synt_rdf.add((versoocciri, tresont.hasInterval, versooccintiri))\n",
    "        synt_rdf.add((versooccintiri, RDF.type, uriinterval))\n",
    "        synt_rdf.add((versooccintiri, tresont.intervalFrom, Literal(libroLength+1, datatype=XSD.integer)))\n",
    "\n",
    "        # versostart=libroLength+1\n",
    "        \n",
    "        synt_rdf.add((versoocciri, tresont.occurrenceOf, versoiri))\n",
    "        versotext=Literal(v, lang='la')\n",
    "        synt_rdf.add((versoiri, RDF.type, tresont.SyntacticEntity))\n",
    "        synt_rdf.add((versoiri, ecrm.P190_has_symbolic_content, versotext))\n",
    "        synt_rdf.add((versoiri, tresont.isPartOf, capiri))\n",
    "        #TESTO\n",
    "        verso=v\n",
    "        for si in punct:\n",
    "            verso=verso.replace(si, '')\n",
    "        verso=verso.replace(\"irri’dentes\",\"irri ’dentes\")\n",
    "        verso=verso.replace(\"et partes* Libyae\",\"et partes * Libyae\")\n",
    "        verso=verso.replace(\"docerent* ei populum\",\"docerent * ei populum\")\n",
    "        verso=verso.replace(\"multiplicantium discipulorum*\",\"multiplicantium discipulorum *\")\n",
    "        verso=verso.replace(\"servitute* redigent\",\"servitute * redigent\")\n",
    "        verso=verso.replace(\"me* quem\",\"me * quem\")\n",
    "        verso=verso.replace(\"impetum* fecerunt\",\"impetum * fecerunt\")\n",
    "        verso=verso.replace(\"Nondum enim'\",\"Nondum enim '\")\n",
    "        verso=verso.replace(\"dantes* eum\", \"dantes * eum\")\n",
    "        verso=verso.replace(\"potestatem a*\", \"potestatem a *\")\n",
    "        verso=verso.replace(\"ecce* venit\",\"ecce * venit\")\n",
    "        verso=verso.replace(\" ut permanent*\",\" ut permanent *\")\n",
    "        verso=verso.replace(\" et contumeliis*\", \" et contumeliis *\")\n",
    "        verso=verso.replace(\" vobis* ab \", \" vobis * ab \")\n",
    "        verso=verso.replace(\"David* quod \", \"David * quod \")\n",
    "        verso=verso.replace(\" saeculo* sunt \", \" saeculo * sunt \")\n",
    "        verso=verso.replace(\" nobis* coactis \",\" nobis * coactis \" )\n",
    "        verso=verso.replace(\" enim sancto* \",\" enim sancto * \")\n",
    "        verso=verso.replace(\" permisit eos* \",\" permisit eos * \")\n",
    "        verso=verso.replace(\" protinus* ostia \",\" protinus * ostia \")\n",
    "        verso=verso.replace(\" viros* quosdam \",\" viros * quosdam \")\n",
    "        verso=verso.replace(\" philosophorum* disserebant \",\" philosophorum * disserebant \")\n",
    "        verso=verso.replace(\" Sosthenem* principem \",\" Sosthenem * principem \")\n",
    "        verso=verso.replace(\" Aculas* qui \",\" Aculas * qui \")\n",
    "        verso=verso.replace(\" Iudaei* principis \",\" Iudaei * principis \")\n",
    "        verso=verso.replace(\" destrui* maiestas \",\" destrui * maiestas \")\n",
    "        verso=verso.replace(\" Asiae constituti* \",\" Asiae constituti * \")\n",
    "        verso=verso.replace(\" Ecclesia* absolvi\",\" Ecclesia * absolvi\")\n",
    "        verso=verso.replace(\" seditionis hodiernae* \",\" seditionis hodiernae * \")\n",
    "        verso=verso.replace(\" Iudaeis* incipienti \",\" Iudaeis * incipienti \")\n",
    "        verso=verso.replace(\"Omnia ostendi* \",\"Omnia ostendi * \")\n",
    "        verso=verso.replace(\" tibi contra* \", \" tibi contra * \")\n",
    "        verso=verso.replace(\" licet vobis* \", \" licet vobis * \")\n",
    "        verso=verso.replace(\" sedes* iudicans \", \" sedes * iudicans \")\n",
    "        verso=verso.replace(\" quam adpropiet* \", \" quam adpropiet * \")\n",
    "        verso=verso.replace(\" nos accusamus* \", \" nos accusamus * \")\n",
    "        verso=verso.replace(\" dicunt* haeresim \", \" dicunt * haeresim \")\n",
    "        verso=verso.replace(\" die* deservientes \", \" die * deservientes \")\n",
    "        verso=verso.replace(\" Romae* vocatis \", \" Romae * vocatis \")\n",
    "        verso=verso.replace(\" Deum* glorificaverunt \", \" Deum * glorificaverunt \")\n",
    "        verso=verso.replace(\"d* \", \"d * \").replace(\"m* \", \"m * \").replace(\"o* \", \"o * \")\n",
    "        verso=verso.replace(\"r* \", \"r * \").replace(\"t* \", \"t * \").replace(\"s* \", \"s * \")\n",
    "        verso=verso.replace(\"i* \", \"i * \").replace(\"e* \", \"e * \").replace('m“ ','m “ ').replace (\"Tamen* \",\"Tamen * \")\n",
    "        verso=verso.replace(\" per * inobedientiam\", \" per* inobedientiam\")\n",
    "        verso=verso.replace(\" liberabitur a* \", \" liberabitur a * \")\n",
    "        verso=verso.replace(\" gloriae** filiorum \", \" gloriae * * filiorum \")\n",
    "        verso=verso.replace(\"a* \", \"a * \").replace(\" et’ \",\" et ’ \")\n",
    "        verso=verso.replace(\" Solutus es * \",\" Solutus es* \")\n",
    "        verso=verso.replace(\" hoc* induerit \",\" hoc * induerit \")\n",
    "        verso=verso.replace(\" hoc* ipsum \",\" hoc * ipsum \")\n",
    "        verso=verso.replace(\" haec* custodias \",\" haec * custodias \")\n",
    "        verso=verso.replace(\" enim haec* dicitur \",\" enim haec * dicitur \")\n",
    "        verso=verso.replace(\" conscientiâ* \",\" conscientiâ * \")\n",
    "        verso=verso.replace(\" sumus per * oblationem \",\" sumus per* oblationem \")\n",
    "        \n",
    "        listaitems=verso.split()\n",
    "        mylemmi_df=df_lemmi[df_lemmi.irifrag==testdf.iloc[i].irifrag]#seleziono i lemmi asociati alle parole\n",
    "        idfrag=testdf.iloc[i].irifrag\n",
    "        for idpa, pa in enumerate(listaitems):\n",
    "            chaptokenindex+=1\n",
    "            pairi=URIRef(its[f'{idOp}_{idbase}_{idfrag}_{idpa+1}_f_se'])\n",
    "            \n",
    "            pairiseq=URIRef(its[f'{idOp}_{idbase}_{idfrag}_{chaptokenindex}_seq'])\n",
    "            pale=pa.strip()\n",
    "            if (pale==mylemmi_df.iloc[idpa].token):\n",
    "                lemma=mylemmi_df.iloc[idpa].lemma\n",
    "                pale=f\"{pale}_{lemma.strip()}\"\n",
    "            else:\n",
    "                print(f\" omg {pa}... {idpa} - {mylemmi_df.iloc[idpa].token} - {testdf.iloc[i].numverso}\")\n",
    "                print(listaitems)\n",
    "            \n",
    "            indicat=''\n",
    "            if (mylemmi_df.iloc[idpa].upos.strip()!='X'):\n",
    "                ciri=f\"{sigleCat[mylemmi_df.iloc[idpa].upos.strip()][1]}\"\n",
    "                adde=''\n",
    "                adde=('').join(re.findall(r'[A-Z]',pale)).lower()\n",
    "                if (adde.strip()!=''):\n",
    "                    if (len (adde)>3):\n",
    "                        adde=adde[0:3]\n",
    "                    adde=f\"-{adde.strip()}\"\n",
    "                indicat=f\"_{ciri}{adde}\"\n",
    "            \n",
    "            # lexical entry    \n",
    "            lepairi=URIRef(its[f'{idOp}_{pale}{indicat}'])\n",
    "            # pairi=URIRef(its[f'{idOp}_{pale}{indicat}_f_se'])\n",
    "            \n",
    "            synt_rdf.add((lepairi, RDF.type, urile))\n",
    "            synt_rdf.add((lepairi, ontolex.lexicalForm, pairi))\n",
    "            \n",
    "            if (pa in punct):\n",
    "                synt_rdf.add((pairi, RDF.type, uripunct))\n",
    "            else:        \n",
    "                synt_rdf.add((pairi, RDF.type, ontolex['Form']))\n",
    "                \n",
    "            synt_rdf.add((pairi, ontolex.writtenRep, Literal(pa, lang='la')))\n",
    "            synt_rdf.add((pairi, tresont.isPartOf, versoiri))\n",
    "            # synt_rdf.add((pairi, tresont.isPartOf, capiri))\n",
    "            \n",
    "            \n",
    "\n",
    "            synt_rdf.add((pairiseq, RDF.type, tresont.TextSequenceElement))\n",
    "            synt_rdf.add((pairiseq, tresont.occurrenceOf, pairi))\n",
    "            synt_rdf.add((pairiseq, tresont.hasPosition, Literal(chaptokenindex, datatype=XSD.integer)))\n",
    "            synt_rdf.add((pairiseq, tresont.inSequence, libroiri))\n",
    "            synt_rdf.add((pairiseq, tresont.inSequence, capocciri))\n",
    "            \n",
    "            #lemma\n",
    "            irilemma=URIRef(its[f'{idOp}_lm_{lemma}{indicat}'])\n",
    "                \n",
    "            lang_rdf.add((irilemma, RDF.type, uritilemma))\n",
    "            lang_rdf.add((irilemma, ontolex.writtenRep, Literal(lemma, lang='la')))\n",
    "            lang_rdf.add((lepairi, ontolex.canonicalForm, irilemma))\n",
    "            if(mylemmi_df.iloc[idpa].upos.strip()!='X'):\n",
    "                categoriav=sigleCat[mylemmi_df.iloc[idpa].upos.strip()][0]\n",
    "                uricatv=URIRef(lila[categoriav])\n",
    "                lang_rdf.add((irilemma, lila['hasPOS'], uricatv))\n",
    "                if (len(mylemmi_df.iloc[idpa].linking)>0):\n",
    "                    sas=mylemmi_df.iloc[idpa].linking[0]\n",
    "                    irisas=''\n",
    "                    if ('lilaLemma:' in sas):\n",
    "                        sas=sas.replace('lilaLemma:', '')\n",
    "                        irisas=URIRef(lilaLemma[sas])\n",
    "                        \n",
    "                    if ('lilaIpoLemma:' in sas):\n",
    "                        sas=sas.replace('lilaIpoLemma:', '')\n",
    "                        irisas=URIRef(lilaIpoLemma[sas])\n",
    "                    if (irisas!=''):    \n",
    "                        lang_rdf.add((irilemma, OWL.sameAs, irisas))\n",
    "               \n",
    "                \n",
    "        libroLength+=len(listaitems)\n",
    "        synt_rdf.add((versooccintiri, tresont.intervalTo, Literal(libroLength, datatype=XSD.integer)))\n",
    "    synt_rdf.add((libroiri, tresont.hasLength, Literal(chaptokenindex, datatype=XSD.integer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b0340-fc14-4572-bd69-7a628fde1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "synt_rdf.serialize(destination=(f'data/output/{siglaopera}_str5_prod.ttl'), format=\"n3\");#format=\"xml\")\n",
    "lang_rdf.serialize(destination=(f'data/output/{siglaopera}_lemmi5__prod.rdf'), format=\"xml\");#format=\"xml\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e4d4d0-87c2-48e5-854d-cc05b12bd29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(synt_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a7704-4ebc-4614-ad57-144cc68df379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lilalemm",
   "language": "python",
   "name": "lilalemm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
