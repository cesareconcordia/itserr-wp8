{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d767f59-fcc3-403b-81b6-565a495fb00b",
   "metadata": {},
   "source": [
    "### Weber Vulgata: creazione del grafo RDF\n",
    "\n",
    "Questo notebook implementa una procedura per la creazione del grafo RDF del testo della Vulgata secondo gli assiomi dell'ontologia [TresOnt](https://docs.google.com/document/d/1n-OlAy1KleovGgHV4ZHhOSgkgMfsOKPDWT603_fic5k/edit?tab=t.0#heading=h.ng7sdvi05k6u).  \n",
    "\n",
    "__Grafo della struttura__ Il testo della Vulgata è trasformato in formato tabellare facendo il parsing dei file <a href=\"https://en.wikipedia.org/wiki/Open_Scripture_Information_Standard\">Open Scripture Information Standard (OSIS)</a> presenti nella <a href=\"https://drive.google.com/drive/folders/1KEFTwR1kLz1Ec_-vU3k-yoFcaynBoP7x\">cartella</a> del drive condiviso del WP8. Alle righe della tabella sono applicate le regole di trasformazione in triple.  \n",
    "__Grafo delle caratteristiche linguistiche__ Alle risorse della struttura sono associate le caratteristiche linguistiche ottenute da LiLa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c1d7a6-8d94-4c0c-b49d-72b932a731b6",
   "metadata": {},
   "source": [
    "####  Librerie e configurazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a77ef3-775b-4818-ab26-9b333ed0baa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "import rdflib\n",
    "from itserr_lib import OsisParser as op\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9869708e-78fb-42d3-9b83-425b2c2314a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.isfile('config.yaml')):\n",
    "    configfile=\"config.yaml\"\n",
    "else:\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), \"config.yaml\")\n",
    "try:\n",
    "    with open(configfile, 'r') as stream:\n",
    "        try:\n",
    "            conf=yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "except FileNotFoundError:\n",
    "    print('Warning config.yaml file not present! Please create it and set the values, store it in the main directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27559b06-a410-4314-9999-5f21d10861be",
   "metadata": {},
   "source": [
    "#### 1 Creo il dataframe con il testo della Vulgata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5fefca1-e276-425f-a6f0-e1622c9368bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=conf['TEXTFILES']\n",
    "source=conf['LIBRI_Vulgata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42dfaa78-04eb-4f52-b75e-abf146a3b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "opars=op()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "273eedc9-177a-4551-8bad-2d86585c61cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 85.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating IRIs...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "df_opera=opars.getDataFrame(source, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73403e9f-ac0a-43c3-a88e-107c09426036",
   "metadata": {},
   "source": [
    "#### 2 Applico le regole per la creazione del grafo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c643a-2eba-4b36-9bc1-506da415347f",
   "metadata": {},
   "source": [
    "Inizializzo la tabella con i lemmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f9dc5c-1699-4ba3-bdd5-79ba180de77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 661358 entries, 0 to 661357\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   index       661358 non-null  int64 \n",
      " 1   token       661358 non-null  object\n",
      " 2   lemma       661358 non-null  object\n",
      " 3   upos        661358 non-null  object\n",
      " 4   spaceAfter  661358 non-null  object\n",
      " 5   linking     661358 non-null  object\n",
      " 6   irifrag     661358 non-null  int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 35.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_lemmi = pd.read_json(path_or_buf='data/output/lemmi.json', orient='table')\n",
    "df_lemmi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d76c173c-7494-484c-b412-99565c429b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>spaceAfter</th>\n",
       "      <th>linking</th>\n",
       "      <th>irifrag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>In</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:106748]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>principio</td>\n",
       "      <td>principium</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:119505]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>creavit</td>\n",
       "      <td>creo</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:96898]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Deus</td>\n",
       "      <td>deus</td>\n",
       "      <td>PROPN</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:4810]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>caelum</td>\n",
       "      <td>caelum</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "      <td>[lilaLemma:92231, lilaLemma:97622]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      token       lemma   upos spaceAfter  \\\n",
       "0      0         In          in    ADP              \n",
       "1      1  principio  principium   NOUN              \n",
       "2      2    creavit        creo   VERB              \n",
       "3      3       Deus        deus  PROPN              \n",
       "4      4     caelum      caelum   NOUN              \n",
       "\n",
       "                              linking  irifrag  \n",
       "0                  [lilaLemma:106748]        0  \n",
       "1                  [lilaLemma:119505]        0  \n",
       "2                   [lilaLemma:96898]        0  \n",
       "3                    [lilaLemma:4810]        0  \n",
       "4  [lilaLemma:92231, lilaLemma:97622]        0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lemmi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3131d8-b0cd-4232-ace4-b9e0a60623b5",
   "metadata": {},
   "source": [
    "Inizializzo i namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7806a6-60c4-44c1-bcd3-fbc0df1c43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.namespace import DC, DCAT, DCTERMS, OWL, \\\n",
    "                            RDF, RDFS, SKOS,  \\\n",
    "                           XMLNS, XSD, XMLNS\n",
    "from rdflib import Namespace\n",
    "from rdflib import URIRef, BNode, Literal\n",
    "its=Namespace(conf['NAMESPACES']['its'])\n",
    "ecrm=Namespace(conf['NAMESPACES']['ecrm'])\n",
    "ontolex=Namespace(conf['NAMESPACES']['ontolex'])\n",
    "tresont=Namespace(conf['NAMESPACES']['tresont'])\n",
    "lila=Namespace(conf['NAMESPACES']['lila'])\n",
    "orl=Namespace(conf['NAMESPACES']['orl'])\n",
    "lilaLemma=Namespace(conf['NAMESPACES']['lilaLemma'])\n",
    "lilaIpoLemma=Namespace(conf['NAMESPACES']['lilaIpoLemma'])\n",
    "\n",
    "siglaopera=conf['SIGLAOPERA']\n",
    "titoloopera=conf['TITOLOOPERA']\n",
    "idencodes=conf['TITOLILIBRI']\n",
    "sigleCat=conf['SIGLEPOS']\n",
    "punct=['.', ',', ':', ';', '?', '!', '†', '※', '(', ')', '-', '..', '\"', '[', ']', '•']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8d7682c-4da6-4fa8-9903-e5fc6e59b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "synt_rdf = rdflib.Graph(identifier = URIRef('https://itserr.it/struct'))\n",
    "lang_rdf = rdflib.Graph(identifier = URIRef('https://itserr.it/lang'))\n",
    "# Declare prefixes\n",
    "synt_rdf.bind(\"its\", its)\n",
    "synt_rdf.bind(\"ecrm\", ecrm)\n",
    "lang_rdf.bind(\"ecrm\", ecrm)\n",
    "synt_rdf.bind(\"tresont\", tresont)\n",
    "lang_rdf.bind(\"tresont\", tresont)\n",
    "synt_rdf.bind(\"orl\", orl)\n",
    "synt_rdf.bind(\"lila\", lila)\n",
    "lang_rdf.bind(\"lila\", lila)\n",
    "synt_rdf.bind(\"ontolex\", ontolex)\n",
    "lang_rdf.bind(\"ontolex\", ontolex)\n",
    "lang_rdf.bind(\"lilaLemma\", lilaLemma)\n",
    "lang_rdf.bind(\"lilaIpoLemma\", lilaIpoLemma)\n",
    "synt_rdf.bind(\"orl\", orl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4716ac7f-0073-4c2b-abfb-82295e6113e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=https://itserr.it/struct (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IRIs\n",
    "\n",
    "workiri=URIRef(its[f'{siglaopera}'])\n",
    "uritf=URIRef(tresont.TextFragment)\n",
    "uriinterval=URIRef(tresont.Interval)\n",
    "opirititle=URIRef(its[f'{siglaopera}_ti'])\n",
    "uritpi=URIRef(tresont.TextualPositionByIndex)\n",
    "urile=URIRef(ontolex.LexicalEntry)\n",
    "uriale= URIRef(tresont.AlphabetElement)\n",
    "uripunct= URIRef(tresont.PunctuationMark)\n",
    "uritilemma=URIRef(ontolex.Form)\n",
    "\n",
    "#Aggiungo le triple al grafo\n",
    "\n",
    "verseindividual=URIRef(tresont['verseType'])\n",
    "chapterindividual=URIRef(tresont['chapterType'])\n",
    "bookindividual=URIRef(tresont['bookType'])\n",
    "synt_rdf.add((verseindividual, RDF.type, tresont.StructuralType))\n",
    "synt_rdf.add((verseindividual, RDFS.label, Literal('Verse', lang='en')))\n",
    "synt_rdf.add((chapterindividual, RDF.type, tresont.StructuralType))\n",
    "synt_rdf.add((chapterindividual, RDFS.label, Literal('Chapter', lang='en')))\n",
    "synt_rdf.add((bookindividual, RDF.type, tresont.StructuralType))\n",
    "synt_rdf.add((bookindividual, RDFS.label, Literal('Book', lang='en')))\n",
    "\n",
    "synt_rdf.add((verseindividual, ecrm.P127_has_broader_term, chapterindividual))\n",
    "synt_rdf.add((chapterindividual, ecrm.P127_has_broader_term, bookindividual))\n",
    "\n",
    "libri=df_opera.libro.unique()\n",
    "synt_rdf.add((workiri, RDF.type, URIRef(tresont.OrderedTextualCollection)))\n",
    "synt_rdf.add((opirititle, RDF.type, ecrm.E35_title))\n",
    "synt_rdf.add((opirititle, RDFS.label, Literal(titoloopera, lang='la')))\n",
    "synt_rdf.add((workiri, ecrm.P102_has_title,opirititle))\n",
    "synt_rdf.add((workiri, tresont.hasLength, Literal(len(libri), datatype=XSD.integer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94dd8c78-2207-4a59-9a63-034bf03ba2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['genesis' 'exodus' 'leviticus' 'numbers' 'deuteronomy' 'joshua' 'judges'\n",
      " 'ruth' 'samuel-1' 'samuel-2' 'kings-1' 'kings-2' 'chronicles-1'\n",
      " 'chronicles-2' 'esdrae-1' 'esdrae-2' 'tobit' 'judith' 'esther' 'job'\n",
      " 'psalms' 'psalms-iuxtra-hebraicum' 'proverbs' 'ecclesiastes'\n",
      " 'song-of-solomon' 'wisdom' 'sirach' 'isaiah' 'jeremiah' 'lamentations'\n",
      " 'baruch' 'ezekiel' 'daniel' 'hosea' 'joel' 'amos' 'obadiah' 'jonah'\n",
      " 'micah' 'nahum' 'habakkuk' 'zephaniah' 'haggai' 'zachariah' 'malachi'\n",
      " 'maccabees-1' 'maccabees-2' 'matthew' 'mark' 'luke' 'john' 'acts'\n",
      " 'romans' 'corinthias-1' 'corinthias-2' 'galatians' 'ephesians'\n",
      " 'philippians' 'colossians' 'thessalonians-1' 'thessalonians-2'\n",
      " 'timothy-1' 'timothy-2' 'titus' 'philemon' 'hebrews' 'james' 'peter-1'\n",
      " 'peter-2' 'john-1' 'john-2' 'john-3' 'jude' 'revelation'\n",
      " 'prayer-of-manasseh' 'esdrae-3' 'esdrae-4' 'psalm-151' 'laodicenses']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [03:12,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# creazione del grafo della struttura dell'opera\n",
    "from tqdm import tqdm\n",
    "bs=0\n",
    "idOp=siglaopera\n",
    "# for libro in tqdm(libri):\n",
    "print(libri)\n",
    "for idlibro, libro in tqdm(enumerate(libri)):\n",
    "    libroLength=0\n",
    "    # idbasekey=f'{libro[0].upper()}{libro[1:]}'\n",
    "    idbasekey=libro\n",
    "    \n",
    "    idbase=idencodes[idbasekey][0]\n",
    "    titololibro=f'{idbasekey[0].upper()}{idbasekey[1:]}'\n",
    "    titololibrolat=idencodes[idbasekey][1]\n",
    "    titololibrolatalt=''\n",
    "    if (len(idencodes[idbasekey])==3):\n",
    "        titololibrolatalt=idencodes[idbasekey][2]\n",
    "    # print(f\" processing {idbase}, {titololibro}, {titololibrolat}, {titololibrolatalt}\")\n",
    "    \n",
    "    bs=idlibro+1\n",
    "    \n",
    "    # LIBRO\n",
    "    libroiri=URIRef(its[f'{idOp}_{idbase}'])\n",
    "    libroirititle=URIRef(its[f'{idOp}_{idbase}_ti'])\n",
    "    libroiriseq=URIRef(its[f'{idOp}_{idbase}_{bs}_seq'])\n",
    "    synt_rdf.add((libroirititle, RDF.type, ecrm.E35_title))\n",
    "    synt_rdf.add((libroirititle, RDFS.label, Literal(titololibro, lang='en')))\n",
    "    synt_rdf.add((libroirititle, RDFS.label, Literal(titololibrolat, lang='la')))\n",
    "    if (titololibrolatalt!=''):\n",
    "        synt_rdf.add((libroirititle, SKOS.altLabel, Literal(titololibrolatalt, lang='la')))\n",
    "    synt_rdf.add((libroiri, RDF.type, tresont.Book))\n",
    "    synt_rdf.add((libroiri, ecrm.P102_has_title, libroirititle))\n",
    "    \n",
    "        \n",
    "    synt_rdf.add((libroiriseq, RDF.type, tresont.TextSequenceElement))\n",
    "    synt_rdf.add((libroiriseq, tresont.occurrenceOf, libroiri))\n",
    "    synt_rdf.add((libroiriseq,tresont.hasPosition, Literal(bs, datatype=XSD.integer)))\n",
    "    synt_rdf.add((libroiriseq,tresont.inSequence, workiri))\n",
    "    synt_rdf.add((workiri, tresont.hasSequenceElement, libroiriseq))\n",
    "    \n",
    "    testdf=df_opera[df_opera.libro==libro].copy() #seleziono i versetti del libro\n",
    "    \n",
    "    testdf.reset_index(drop=True, inplace=True)\n",
    "    cps={'test'}\n",
    "    prevchap=''\n",
    "    chaptokenindex=0\n",
    "    for i, v in testdf['testo'].items():\n",
    "       \n",
    "        # CAPITOLO\n",
    "        # print (testdf.iloc[i].numcap+', '+v)\n",
    "        if (not testdf.iloc[i].numcap in cps):\n",
    "            \n",
    "            idcapitolo=(testdf.iloc[i].numcap).split(\".\")[1]  \n",
    "            capoccintiri=URIRef(its[f'{idOp}_{idbase}_{idcapitolo}_i'])\n",
    "            capocciri=URIRef(its[f'{idOp}_{idbase}_{idcapitolo}_o'])\n",
    "            capiri=URIRef(its[f'{idOp}_{idbase}_{idcapitolo}_c_se'])\n",
    "            synt_rdf.add((capocciri, RDF.type, uritf))\n",
    "            synt_rdf.add((capocciri, tresont.hasStructuralType, chapterindividual))\n",
    "            synt_rdf.add((capocciri, tresont.hasNumber, Literal(idcapitolo, datatype=XSD.integer)))\n",
    "            synt_rdf.add((capocciri, tresont.inSequence, libroiri))\n",
    "            synt_rdf.add((capocciri, tresont.occurrenceOf, capiri))\n",
    "            synt_rdf.add((capiri, RDF.type, tresont.SyntacticEntity))\n",
    "            \n",
    "            #Intervallo del capitolo\n",
    "            synt_rdf.add((capocciri, tresont.hasInterval, capoccintiri))\n",
    "            synt_rdf.add((capoccintiri, RDF.type, uriinterval))\n",
    "            synt_rdf.add((capoccintiri, tresont.intervalFrom, Literal(libroLength+1, datatype=XSD.integer)))\n",
    "            if(prevchap==''):\n",
    "                prevchap=capoccintiri\n",
    "            else:\n",
    "                synt_rdf.add((prevchap, tresont.intervalTo, Literal(libroLength, datatype=XSD.integer)))\n",
    "                prevchap=capoccintiri\n",
    "            cps.add(testdf.iloc[i].numcap)\n",
    "        \n",
    "        #OCCORRENZA VERSO\n",
    "        # print(testdf.iloc[i].numverso)\n",
    "        versoocciri=URIRef(its[f'{idOp}_{idbase}_{idcapitolo}_{testdf.iloc[i].numverso}_o'])\n",
    "        versooccintiri=URIRef(its[f'{idOp}_{idbase}_{idcapitolo}_{testdf.iloc[i].numverso}_i'])\n",
    "        versoiri=URIRef(its[f'{idOp}_{testdf.iloc[i].irifrag}_v_se'])\n",
    "    \n",
    "        synt_rdf.add((versoocciri, RDF.type, uritf))\n",
    "        synt_rdf.add((versoocciri, tresont.hasStructuralType, verseindividual))\n",
    "        synt_rdf.add((versoocciri, tresont.hasNumber, Literal(testdf.iloc[i].numverso, datatype=XSD.integer)))\n",
    "        synt_rdf.add((versoocciri, tresont.inSequence, libroiri))\n",
    "        synt_rdf.add((versoocciri, tresont.inSequence, capocciri))\n",
    "        \n",
    "        #Intervallo del verso\n",
    "        synt_rdf.add((versoocciri, tresont.hasInterval, versooccintiri))\n",
    "        synt_rdf.add((versooccintiri, RDF.type, uriinterval))\n",
    "        synt_rdf.add((versooccintiri, tresont.intervalFrom, Literal(libroLength+1, datatype=XSD.integer)))\n",
    "\n",
    "        # versostart=libroLength+1\n",
    "        \n",
    "        synt_rdf.add((versoocciri, tresont.occurrenceOf, versoiri))\n",
    "        versotext=Literal(v, lang='la')\n",
    "        synt_rdf.add((versoiri, RDF.type, tresont.SyntacticEntity))\n",
    "        synt_rdf.add((versoiri, ecrm.P190_has_symbolic_content, versotext))\n",
    "        synt_rdf.add((versoiri, tresont.isPartOf, capiri))\n",
    "        #TESTO\n",
    "        verso=v\n",
    "        for si in punct:\n",
    "            verso=verso.replace(si, '')\n",
    "        listaitems=verso.split()\n",
    "        mylemmi_df=df_lemmi[df_lemmi.irifrag==testdf.iloc[i].irifrag]#seleziono i lemmi asociati alle parole\n",
    "        idfrag=testdf.iloc[i].irifrag\n",
    "        #aggiunto per problema pairiseq\n",
    "        vnumt=testdf.iloc[i].numverso\n",
    "        for idpa, pa in enumerate(listaitems):\n",
    "            chaptokenindex+=1\n",
    "            pairi=URIRef(its[f'{idOp}_{idbase}_{idfrag}_{idpa+1}_f_se'])\n",
    "\n",
    "            # pairi=URIRef(its[f'{idOp}_{idbase}_f_se'])\n",
    "            \n",
    "            pairiseq=URIRef(its[f'{idOp}_{idbase}_{idcapitolo}_{vnumt}_{idfrag}_{chaptokenindex}_seq'])\n",
    "            pale=pa.strip()\n",
    "            if (pale==mylemmi_df.iloc[idpa].token):\n",
    "                lemma=mylemmi_df.iloc[idpa].lemma\n",
    "                pale=f\"{pale}_{lemma.strip()}\"\n",
    "            else:\n",
    "                print(f\" omg {pa}... {idpa} - {mylemmi_df.iloc[idpa].token} - {testdf.iloc[i].testo}\")\n",
    "                print(listaitems)\n",
    "            \n",
    "            indicat=''\n",
    "            if (mylemmi_df.iloc[idpa].upos.strip()!='X'):\n",
    "                ciri=f\"{sigleCat[mylemmi_df.iloc[idpa].upos.strip()][1]}\"\n",
    "                adde=''\n",
    "                adde=('').join(re.findall(r'[A-Z]',pale)).lower()\n",
    "                if (adde.strip()!=''):\n",
    "                    if (len (adde)>3):\n",
    "                        adde=adde[0:3]\n",
    "                    adde=f\"-{adde.strip()}\"\n",
    "                indicat=f\"_{ciri}{adde}\"\n",
    "            \n",
    "            # lexical entry    \n",
    "            lepairi=URIRef(its[f'{idOp}_{pale}{indicat}'])\n",
    "            # pairi=URIRef(its[f'{idOp}_{pale}{indicat}_f_se'])\n",
    "            \n",
    "            synt_rdf.add((lepairi, RDF.type, urile))\n",
    "            synt_rdf.add((lepairi, ontolex.lexicalForm, pairi))\n",
    "            \n",
    "            if (pa in punct):\n",
    "                synt_rdf.add((pairi, RDF.type, uripunct))\n",
    "            else:        \n",
    "                synt_rdf.add((pairi, RDF.type, ontolex['Form']))\n",
    "                \n",
    "            synt_rdf.add((pairi, ontolex.writtenRep, Literal(pa, lang='la')))\n",
    "            synt_rdf.add((pairi, tresont.isPartOf, versoiri))\n",
    "            # synt_rdf.add((pairi, tresont.isPartOf, capiri))\n",
    "            \n",
    "            \n",
    "\n",
    "            synt_rdf.add((pairiseq, RDF.type, tresont.TextSequenceElement))\n",
    "            synt_rdf.add((pairiseq, tresont.occurrenceOf, pairi))\n",
    "            synt_rdf.add((pairiseq, tresont.hasPosition, Literal(chaptokenindex, datatype=XSD.integer)))\n",
    "            synt_rdf.add((pairiseq, tresont.inSequence, libroiri))\n",
    "            synt_rdf.add((pairiseq, tresont.inSequence, capocciri))\n",
    "            \n",
    "            #lemma\n",
    "            irilemma=URIRef(its[f'{idOp}_lm_{lemma}{indicat}'])\n",
    "                \n",
    "            lang_rdf.add((irilemma, RDF.type, uritilemma))\n",
    "            lang_rdf.add((irilemma, ontolex.writtenRep, Literal(lemma, lang='la')))\n",
    "            lang_rdf.add((lepairi, ontolex.canonicalForm, irilemma))\n",
    "            if(mylemmi_df.iloc[idpa].upos.strip()!='X'):\n",
    "                categoriav=sigleCat[mylemmi_df.iloc[idpa].upos.strip()][0]\n",
    "                uricatv=URIRef(lila[categoriav])\n",
    "                lang_rdf.add((irilemma, lila['hasPOS'], uricatv))\n",
    "                if (len(mylemmi_df.iloc[idpa].linking)>0):\n",
    "                    sas=mylemmi_df.iloc[idpa].linking[0]\n",
    "                    irisas=''\n",
    "                    if ('lilaLemma:' in sas):\n",
    "                        sas=sas.replace('lilaLemma:', '')\n",
    "                        irisas=URIRef(lilaLemma[sas])\n",
    "                        \n",
    "                    if ('lilaIpoLemma:' in sas):\n",
    "                        sas=sas.replace('lilaIpoLemma:', '')\n",
    "                        irisas=URIRef(lilaIpoLemma[sas])\n",
    "                    if (irisas!=''):    \n",
    "                        lang_rdf.add((irilemma, OWL.sameAs, irisas))\n",
    "               \n",
    "                \n",
    "        libroLength+=len(listaitems)\n",
    "        synt_rdf.add((versooccintiri, tresont.intervalTo, Literal(libroLength, datatype=XSD.integer)))\n",
    "    synt_rdf.add((libroiri, tresont.hasLength, Literal(chaptokenindex, datatype=XSD.integer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b0340-fc14-4572-bd69-7a628fde1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "synt_rdf.serialize(destination=(f'data/output/{siglaopera}_str_prod_test.ttl'), format=\"n3\");#format=\"xml\")\n",
    "lang_rdf.serialize(destination=(f'data/output/{siglaopera}_lemmi1__prod_test.rdf'), format=\"xml\");#format=\"xml\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e4d4d0-87c2-48e5-854d-cc05b12bd29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(synt_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a7704-4ebc-4614-ad57-144cc68df379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lilalemm",
   "language": "python",
   "name": "lilalemm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
